<html lang="en"><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Installation NexentaEdge DevOps Edition · NexentaEdge</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta property="og:title" content="Installation NexentaEdge DevOps Edition · NexentaEdge"/><meta property="og:type" content="website"/><meta property="og:url" content="http://nexentaedge.io/index.html"/><meta property="og:description" content="NexentaEdge is designed to run in Linux containers, as bare-metal on-premise or inside a virtual machine in the cloud. It is high performance scale-out storage solution with File, Block and Object interfaces tightly integrated with container application frameworks."/><link rel="shortcut icon" href="/img/favicon.png"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.css"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="http://nexentaedge.io/blog/atom.xml" title="NexentaEdge Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="http://nexentaedge.io/blog/feed.xml" title="NexentaEdge Blog RSS Feed"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script type="text/javascript" src="https://use.fontawesome.com/releases/v5.0.8/js/all.js"></script><script type="text/javascript" src="https://unpkg.com/mermaid@8.0.0-rc.6/dist/mermaid.min.js"></script><script type="text/javascript" src="/js/main.js"></script><link rel="stylesheet" href="/css/main.css"/></head><body class="sideNavVisible"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/"><img class="logo" src="/img/logo-nexenta-full.png"/></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li><a href="/docs/introduction.html" target="_self">Documentation</a></li><li><a href="/blog" target="_self">Blog</a></li><li class="navSearchWrapper reactNavSearchWrapper"><input type="text" id="search_input_react" placeholder="Search"/></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="container docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><i></i></div><h2><i>›</i><span>Getting Started</span></h2></div><div class="navGroups"><div class="navGroup navGroupActive"><h3>Getting Started</h3><ul><li class="navListItem"><a class="navItem" href="/docs/introduction.html">Introduction</a></li><li class="navListItem navListItemActive"><a class="navItem navItemActive" href="/docs/installation.html">Installation</a></li><li class="navListItem"><a class="navItem" href="/docs/installation-ui.html">Installation UI</a></li><li class="navListItem"><a class="navItem" href="/docs/network-considerations.html">Networking Considerations</a></li><li class="navListItem"><a class="navItem" href="/docs/multi-tenant-and-kubernetes.html">Multi-Tenant and Kubernetes</a></li></ul></div><div class="navGroup navGroupActive"><h3>Guides</h3><ul><li class="navListItem"><a class="navItem" href="/docs/using-docker.html">Using Docker</a></li></ul></div><div class="navGroup navGroupActive"><h3>Online Resources</h3><ul><li class="navListItem"><a class="navItem" href="/docs/online-resources.html">Online Resoures</a></li></ul></div></div></section></div><script>
          var toggler = document.getElementById('navToggler');
          var nav = document.getElementById('docsNav');
          toggler.onclick = function() {
            nav.classList.toggle('docsSliderActive');
          };
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><a class="edit-page-link button" href="https://github.com/nexentaedge/nexentaedge.github.io/edit/master/src/docs/installation.md" target="_blank">Edit</a><h1>Installation NexentaEdge DevOps Edition</h1></header><article><div><span><p>NexentaEdge is designed to run in Linux containers, as bare-metal on-premise or inside a virtual machine in the cloud. It is high performance scale-out storage solution with File, Block and Object interfaces tightly integrated with container application frameworks.</p>
<p>To install NexentaEdge DevOps Edition you need at least one Linux server meeting the requirements listed below.</p>
<h3><a class="anchor" aria-hidden="true" name="requirements-and-limitations"></a><a href="#requirements-and-limitations" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Requirements and Limitations</h3>
<p>It is highly recommended that you run NexentaEdge DevOps Edition on a system with at least 16GB RAM.</p>
<table>
<thead>
<tr><th>Requirement</th><th>Notes</th></tr>
</thead>
<tbody>
<tr><td>OS</td><td>Ubuntu 16.04 LTS, CentOS/RHEL 7.2 (with ELRepo enabled)</td></tr>
<tr><td>Kernel Version</td><td>4.4 or higher</td></tr>
<tr><td>Docker Version</td><td>1.12 or higher</td></tr>
<tr><td>CPU</td><td>4 cores minimally recommended</td></tr>
<tr><td>Memory</td><td>16GB Minimum + 2GB x # of HDDs</td></tr>
<tr><td>Management Network</td><td>Connected to management 1G switch (optional)</td></tr>
<tr><td>Client I/O Network</td><td>Shared with clients network, 1G - 100G</td></tr>
<tr><td>Replicast I/O Network</td><td>Dedicated, VLAN isolated networking, MTU 9000 (required), 1G - 100G</td></tr>
<tr><td>Minimum individual Disk size</td><td>1GB</td></tr>
<tr><td>Minimal number of disks per Data Container</td><td>4</td></tr>
<tr><td>Max raw capacity per Data Container</td><td>up to 132TB</td></tr>
</tbody>
</table>
<p>NexentaEdge DevOps licensing limitations:</p>
<table>
<thead>
<tr><th>Resource</th><th>Limit</th></tr>
</thead>
<tbody>
<tr><td>Max Total Logical Used Capacity (*)</td><td>16TB</td></tr>
<tr><td>Max Number of Data Containers</td><td>4</td></tr>
<tr><td>Max Number of GW Containers</td><td>Unlimited</td></tr>
</tbody>
</table>
<p>(*) Logical Used Capacity is what application logically allocates. Example would be: iSCSI LUN of 1TB would allocate 1TB of logical. The other example would be: while total raw capacity of 4 servers is 256TB it is still possible to install software with DevOps license initially and then later convert it to unlimited Enterprise (try and then buy model)</p>
<h3><a class="anchor" aria-hidden="true" name="example-of-single-node-setup-one-data-gw-container-running-s3-service"></a><a href="#example-of-single-node-setup-one-data-gw-container-running-s3-service" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example of single node setup (one Data+GW container), running S3 service</h3>
<p>Follow below steps to get familiarity with NexentaEdge by trying &quot;all-in-one&quot; deployment where Data and GW functions running in the same single container.</p>
<p>Before you start, please verify and decide:</p>
<ul>
<li><p>You have a baremetal server or virtual machine which satisfies the above requirements. If you planning to use VirtulBox then please make sure to use VirtIO networking interface for Replicast</p></li>
<li><p>If you planning to build multi-host network for 3-node cluster setup, ensure that networking is setup correctly. I.e. at the very minimum on every host you will need to provide two networking interfaces, one for the client I/O and the other one (VLAN isolated) for the backend I/O. NexentaEdge using high-performance IPv6 UDP (Unicast and optionally Multicast) to achieve low latency and high throughput storage I/O transfers. Ensure that backend network is reliably connected, isolated, set to use jumbo frames and optionally flow-control enabled</p></li>
</ul>
<h3><a class="anchor" aria-hidden="true" name="step-1-setting-up-replicast-network"></a><a href="#step-1-setting-up-replicast-network" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 1: Setting up Replicast network</h3>
<p>NexentaEdge designed for high performance and massive scalability beyond 1000 servers per single namespace physical cluster. It doesn't need to have central metadata server(s) or coordination server(s). Architecture is true &quot;shared nothing&quot; with metadata and data fully distributed across the cluster. To operate optimally NexentaEdge needs dedicated high-performance network for cluster backend, isolated with VLAN segment, set for use of Jumbo Frames and preferably non-blocking switch with Flow-Control enabled. There are 3 supported options to get Replicast Network configured:</p>
<ol>
<li><p>Using Docker provided &quot;--network host&quot; start parameter. Please refer to Docker documentation for details. This option is the simplest and that is what we use in our examples below</p></li>
<li><p>Can be emulated with Docker macvlan driver. Please refer to Docker documentation for details. Example:</p></li>
</ol>
<pre><code class="hljs">ifconfig enp0s9 mtu 9000 up
modprobe macvlan
docker<span class="hljs-built_in"> network </span>create -d macvlan --subnet 192.168.10.0/24 -o <span class="hljs-attribute">parent</span>=enp0s9 replicast_net
</code></pre>
<ol start="3">
<li>Use OpenVSwitch bridge. (Instructions coming soon)</li>
</ol>
<p>Activation script needs to ensure that all networks exists and functional prior to starting container.</p>
<h3><a class="anchor" aria-hidden="true" name="step-2-prepare-nesetupjson-file-raw-disks-and-set-optimal-host-sysctl-parameters"></a><a href="#step-2-prepare-nesetupjson-file-raw-disks-and-set-optimal-host-sysctl-parameters" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 2: Prepare nesetup.json file, raw disks and set optimal host sysctl parameters</h3>
<ul>
<li>edit <a href="https://github.com/Nexenta/nedge-dev/blob/master/conf/single-node/nesetup.json">nesetup.json</a> - <a href="https://raw.githubusercontent.com/Nexenta/nedge-dev/master/conf/single-node/nesetup.json">download</a> from &quot;single-node&quot; profile (located in conf directory) and copy it over to some dedicated container directory, e.g. /root/c0</li>
<li>adjust broker_interfaces, example eth1. This is backend gateway container interface (Replicast)</li>
<li>server_interfaces point to the same name, example eth1. This is also backend but for data container interface (Replicast)</li>
<li>adjust rtrd section to point to the devices to be used. You can identify DEVID and JOURNAL_DEVID names by running this command:</li>
</ul>
<pre><code class="hljs">ls /dev/disk/<span class="hljs-keyword">by</span>-<span class="hljs-built_in">id</span>|grep -v <span class="hljs-string">"\-part"</span>
</code></pre>
<ul>
<li>Use nezap utility to zap device(s). WARNING: ALL DATA ON SELECTED DISKS WILL BE WIPED OUT. Example:</li>
</ul>
<pre><code class="hljs">docker run <span class="hljs-params">--rm</span> <span class="hljs-params">--privileged=true</span> -v <span class="hljs-string">/dev</span>:<span class="hljs-string">/dev</span> nexenta/nedge <span class="hljs-string">/opt/nedge/sbin/nezap</span> <span class="hljs-params">--do-as-i-say</span> DEVID [JOURNAL_DEVID]
</code></pre>
<p>Make sure to zap all the devices you listed in nesetup.json. Use optional JOURNAL_DEVID parameter to additionally zap journal/cache SSD.</p>
<p>Set optimal host sysctl parameters:</p>
<pre><code class="hljs">echo <span class="hljs-string">"net.ipv6.conf.all.force_mld_version = 1"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.core.optmem_max = 131072"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.core.netdev_max_backlog = 300000"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.core.rmem_default = 80331648"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.core.rmem_max = 80331648"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.core.wmem_default = 33554432"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.core.wmem_max = 50331648"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"vm.dirty_ratio = 10"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"vm.dirty_background_ratio = 5"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"vm.dirty_expire_centisecs = 6000"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"vm.swappiness = 25"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.ipv4.tcp_fastopen = 3"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.ipv4.tcp_mtu_probing = 1"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.ipv6.ip6frag_high_thresh = 10000000"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.ipv6.ip6frag_low_thresh = 7000000"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
echo <span class="hljs-string">"net.ipv6.ip6frag_time = 120"</span> &gt;&gt; /etc/sysctl<span class="hljs-selector-class">.conf</span>
sysctl -<span class="hljs-selector-tag">p</span>
</code></pre>
<p>See <a href="#Reference">Reference</a> for detailed explanations for these.</p>
<h3><a class="anchor" aria-hidden="true" name="step-3-start-data-and-gw-container-as-a-single-instance-case"></a><a href="#step-3-start-data-and-gw-container-as-a-single-instance-case" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 3: Start Data and GW Container (as a single instance case)</h3>
<ul>
<li>create empty var directory. This directory will persistently keep containers information necesary to have across restarts and reboots.</li>
</ul>
<pre><code class="hljs"><span class="hljs-built_in">mkdir</span> /root/c0/<span class="hljs-built_in">var</span>
</code></pre>
<ul>
<li>starting with host networking configuration. Ensure that host has ports 8080 and 9982 not used and available. Port 8080 (default) will be used to respond to REST API requests and 9982 (default) will be used to serve S3 requests</li>
</ul>
<pre><code class="hljs">netstat -ant|grep <span class="hljs-string">"8080\|9982"</span>|grep LISTEN
docker run --ipc host --network host --name nedge-data-s3 \
    -e HOST_HOSTNAME=$(hostname) -e CCOW_SVCNAME=s3finance -d -t -i --privileged=<span class="hljs-literal">true</span> \
    -v <span class="hljs-regexp">/root/</span>c0<span class="hljs-regexp">/var:/</span>opt<span class="hljs-regexp">/nedge/</span>var \
    -v <span class="hljs-regexp">/root/</span>c0<span class="hljs-regexp">/nesetup.json:/</span>opt<span class="hljs-regexp">/nedge/</span>etc<span class="hljs-regexp">/ccow/</span>nesetup.<span class="hljs-string">json:</span>ro \
    -v <span class="hljs-regexp">/dev:/</span>dev \
    -v <span class="hljs-regexp">/etc/</span><span class="hljs-string">localtime:</span><span class="hljs-regexp">/etc/</span><span class="hljs-string">localtime:</span>ro \
        nexenta/nedge start -j ccowserv -j ccowgws3
</code></pre>
<h3><a class="anchor" aria-hidden="true" name="step-4-initialize-cluster-and-obtain-license"></a><a href="#step-4-initialize-cluster-and-obtain-license" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 4: Initialize cluster and obtain license</h3>
<ul>
<li>copy <a href="https://github.com/Nexenta/nedge-dev/blob/master/conf/default/.neadmrc">.neadmrc</a> - <a href="https://raw.githubusercontent.com/Nexenta/nedge-dev/master/conf/default/.neadmrc">download</a> from &quot;default&quot; profile (located in conf directory) to /root/c0. If you planning to use neadm tool on a different host, you'll need to adjust API_URL to point to the right management IPv4 address. Default port 8080, and add &quot;-v /root/c0/.neadmrc:/opt/neadm/.neadmrc&quot; to the alias</li>
<li>source <a href="https://github.com/Nexenta/nedge-dev/blob/master/conf/default/.bash_completion">.bash_completion</a> - <a href="https://raw.githubusercontent.com/Nexenta/nedge-dev/master/conf/default/.bash_completion">download</a> from &quot;default&quot; profile (located in conf directory). This is optional step.</li>
<li>setup neadm alias (optional)</li>
</ul>
<pre><code class="hljs"><span class="hljs-symbol">source</span> /root/<span class="hljs-built_in">c0</span>/.<span class="hljs-keyword">bash_completion
</span><span class="hljs-symbol">docker</span> pull nexenta/nedge-neadm
<span class="hljs-symbol">alias</span> neadm=<span class="hljs-string">"docker run -i -t --rm -v /root/c0/.neadmrc:/opt/neadm/.neadmrc --network host nexenta/nedge-neadm /opt/neadm/neadm"</span>
</code></pre>
<ul>
<li>use NEADM management tool to verify that data container(s) are online</li>
</ul>
<pre><code class="hljs">neadm<span class="hljs-built_in"> system </span>status
</code></pre>
<ul>
<li>use NEADM management tool to initialize cluster</li>
</ul>
<pre><code class="hljs">neadm<span class="hljs-built_in"> system </span>init
</code></pre>
<ul>
<li>register DevOps account <a href="https://community.nexenta.com/s/devops-edition">here</a></li>
<li>use e-mailed activation key to activate installation:</li>
</ul>
<pre><code class="hljs">neadm<span class="hljs-built_in"> system </span>license <span class="hljs-builtin-name">set</span> online LICENSE-ACTIVATION-KEY
</code></pre>
<h3><a class="anchor" aria-hidden="true" name="step-5-create-service-configuration"></a><a href="#step-5-create-service-configuration" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 5: Create service configuration</h3>
<ul>
<li>use NEADM management tool to create cluster name space &quot;company-branch1&quot; and tenant &quot;finance&quot;</li>
</ul>
<pre><code class="hljs"><span class="hljs-symbol">neadm</span> cluster create company-<span class="hljs-keyword">branch1
</span><span class="hljs-symbol">neadm</span> tenant create company-<span class="hljs-keyword">branch1/finance
</span></code></pre>
<ul>
<li>use NEADM management tool to setup service parameters</li>
</ul>
<pre><code class="hljs">neadm<span class="hljs-built_in"> service </span>create s3 s3finance
neadm<span class="hljs-built_in"> service </span>serve s3finance company-branch1/finance
</code></pre>
<ul>
<li>restart s3 service so that it will pick up new values from the &quot;s3finance&quot; service definition. This operation only required when data and gateway (S3) container running in the same instance</li>
</ul>
<pre><code class="hljs"><span class="hljs-symbol">docker</span> exec -<span class="hljs-keyword">it </span>nedge-<span class="hljs-meta">data</span>-<span class="hljs-built_in">s3</span> /<span class="hljs-meta">opt</span>/nedge/nmf/nefcmd.sh adm restart ccowgws3
</code></pre>
<h3><a class="anchor" aria-hidden="true" name="step-6-verify-that-service-is-running"></a><a href="#step-6-verify-that-service-is-running" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 6: Verify that service is running</h3>
<pre><code class="hljs">curl <span class="hljs-string">http:</span><span class="hljs-comment">//localhost:9982/</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" name="example-of-3-node-setup-running-s3-service-nginx-proxy-and-load-balancer"></a><a href="#example-of-3-node-setup-running-s3-service-nginx-proxy-and-load-balancer" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Example of 3-node setup, running S3 service NGINX proxy and load balancer</h2>
<p>Follow below steps to get familiarity with NexentaEdge by trying simple 3-node deployment where Data and GW functions running in the same container, serving S3 protocol with NGNIX load balancing HTTP requests</p>
<h3><a class="anchor" aria-hidden="true" name="step-1-setting-up-replicast-network-for-3-node-cluster"></a><a href="#step-1-setting-up-replicast-network-for-3-node-cluster" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 1: Setting up Replicast network for 3-node cluster</h3>
<p>Follow same networking configuration for all the 3 nodes as described in &quot;single-node&quot; example above. Make sure that networking interfaces are all configured with Jumbo and accessible in isolated VLAN (physical or emulated).</p>
<h3><a class="anchor" aria-hidden="true" name="step-2-prepare-nesetupjson-file-raw-disks-and-set-optimal-host-sysctl-parameters"></a><a href="#step-2-prepare-nesetupjson-file-raw-disks-and-set-optimal-host-sysctl-parameters" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 2: Prepare nesetup.json file, raw disks and set optimal host sysctl parameters</h3>
<p>Follow same disk configuration for all the 3 nodes as described in &quot;single-node&quot; example above with following differences and additional stps:</p>
<ul>
<li>you will need to use and edit <a href="https://github.com/Nexenta/nedge-dev/blob/master/conf/default/nesetup.json">nesetup.json</a> - <a href="https://raw.githubusercontent.com/Nexenta/nedge-dev/master/conf/default/nesetup.json">download</a> from &quot;default&quot; profile. Or use appropriate profile to enable SSD cache/journaling for high-performance hybrid configuration. Consider to use throughput profile if your use case is mostly large objects / files</li>
<li>select one of containers also to have management role by changing &quot;is_aggregator&quot; to 1</li>
</ul>
<h3><a class="anchor" aria-hidden="true" name="step-3-start-data-and-gw-container-as-a-single-instance-on-each-node"></a><a href="#step-3-start-data-and-gw-container-as-a-single-instance-on-each-node" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 3: Start Data and GW Container (as a single instance) on each node</h3>
<p>Follow same container start steps as described in &quot;single-node&quot; example above. NexentaEdge will automatically discover new nodes and form a cluster.</p>
<h3><a class="anchor" aria-hidden="true" name="step-4-initialize-cluster-and-obtain-license"></a><a href="#step-4-initialize-cluster-and-obtain-license" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 4: Initialize cluster and obtain license</h3>
<p>Follow same initialization steps as described in &quot;single-node&quot; example above. Make sure to modify .neadmrc to set IPv4 address to point to a node with selected management role (i.e. where is_aggregator=1 in nesetup.json)</p>
<h3><a class="anchor" aria-hidden="true" name="step-5-create-service-configuration"></a><a href="#step-5-create-service-configuration" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 5: Create service configuration</h3>
<p>Follow same service configuration steps as described in &quot;single-node&quot; example above.</p>
<ul>
<li>restart s3 service on each node, so that it will pick up new values from the &quot;s3finance&quot; service definition</li>
</ul>
<pre><code class="hljs"><span class="hljs-symbol">docker</span> exec -<span class="hljs-keyword">it </span>nedge-<span class="hljs-meta">data</span>-<span class="hljs-built_in">s3</span> /<span class="hljs-meta">opt</span>/nedge/nmf/nefcmd.sh adm restart ccowgws3
</code></pre>
<h3><a class="anchor" aria-hidden="true" name="step-6-setup-nginx-load-balancer-proxy"></a><a href="#step-6-setup-nginx-load-balancer-proxy" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 6: Setup nginx load balancer proxy</h3>
<p>The goal is to set up an installation that has an Nginx reverse proxy server at the front and a set of upstream servers handling the requests. The Nginx server is the one directly communicating with clients. Clients don’t receive any information about particular upstream server handling their requests. The responses appear to come directly from the reverse proxy server.</p>
<p>Assuming that Edge containers running on servers with public IPv4 addresses (10.1.1.10, 10.1.1.11, 10.1.1.12), create simple reverse proxy configuration file:</p>
<pre><code class="hljs">mkdir <span class="hljs-meta-keyword">/root/</span>nginx
cat <span class="hljs-params">&lt;&lt; EOF &gt;</span> <span class="hljs-meta-keyword">/root/</span>nginx/nedge.conf
upstream <span class="hljs-class">servers </span>{
    ip_hash;
    server <span class="hljs-number">10.1</span><span class="hljs-number">.1</span><span class="hljs-number">.10</span>:<span class="hljs-number">9982</span>;
    server <span class="hljs-number">10.1</span><span class="hljs-number">.1</span><span class="hljs-number">.11</span>:<span class="hljs-number">9982</span>;
    server <span class="hljs-number">10.1</span><span class="hljs-number">.1</span><span class="hljs-number">.12</span>:<span class="hljs-number">9982</span>;
}

<span class="hljs-class">server </span>{
    listen <span class="hljs-number">9980</span>;
    client_max_body_size <span class="hljs-number">0</span>;
    proxy_http_version <span class="hljs-number">1.1</span>;
    proxy_request_buffering off;

    location <span class="hljs-class">/ {
        proxy_pass http:<span class="hljs-comment">//servers;</span>
    }
}
EOF
</span></code></pre>
<p>And start ngnix proxy container:</p>
<pre><code class="hljs">docker run -<span class="hljs-selector-tag">td</span> -<span class="hljs-selector-tag">p</span> <span class="hljs-number">80</span>:<span class="hljs-number">9980</span> --name nginx-proxy \
    -v /var/run/docker<span class="hljs-selector-class">.sock</span>:/tmp/docker<span class="hljs-selector-class">.sock</span>:ro \
    -v /root/nginx/nedge<span class="hljs-selector-class">.conf</span>:/etc/nginx/conf.d/nedge<span class="hljs-selector-class">.conf</span>:ro \
    jwilder/nginx-proxy
</code></pre>
<h3><a class="anchor" aria-hidden="true" name="step-7-verify-that-s3-proxy-service-is-running"></a><a href="#step-7-verify-that-s3-proxy-service-is-running" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Step 7: Verify that S3 proxy service is running</h3>
<p>Observe that ngnix-proxy host (replace with IP address to access proxy) can transparently proxy and load-balance S3 requests to Edge cluster:</p>
<pre><code class="hljs">curl <span class="hljs-string">http:</span><span class="hljs-comment">//ngnix-proxy:80/</span>
</code></pre>
<h1><a class="anchor" aria-hidden="true" name="contact-us"></a><a href="#contact-us" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Contact Us</h1>
<p>As you use NexentaEdge, please share your feedback and ask questions. Find the team on <a href="https://community.nexenta.com/s/topic/0TOU0000000brtXOAQ/nexentaedge">NexentaEdge Forum</a>.</p>
<p>If your requirements extend beyond the scope of DevOps Edition, then please contact <a href="https://nexenta.com/contact-us">Nexenta</a> for information on NexentaEdge Enterprise Edition.</p>
<h2><a class="anchor" aria-hidden="true" name="a-name-reference-a-reference"></a><a href="#a-name-reference-a-reference" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><a name="Reference"></a>Reference</h2>
<h2><a class="anchor" aria-hidden="true" name="description-of-nesetupjson"></a><a href="#description-of-nesetupjson" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Description of nesetup.json</h2>
<h3><a class="anchor" aria-hidden="true" name="section-ccow"></a><a href="#section-ccow" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Section &quot;ccow&quot;</h3>
<p>This file defines configuration used by CCOW client library.</p>
<table>
<thead>
<tr><th>Field</th><th>Description</th><th>Example</th><th>Required</th></tr>
</thead>
<tbody>
<tr><td>tenant/failure_domain</td><td>Defines desirable failure domain for the container. 0 - single node, 1 - server, 2 - zone</td><td>1</td><td>required</td></tr>
<tr><td>network/broker_interfaces</td><td>The network interface for GW function, can be same as in ccowd.json</td><td>eth0</td><td>required</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" name="section-ccowd"></a><a href="#section-ccowd" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Section &quot;ccowd&quot;</h3>
<p>This file defines configuration used by CCOW daemon.</p>
<table>
<thead>
<tr><th>Field</th><th>Description</th><th>Example</th><th>Required</th></tr>
</thead>
<tbody>
<tr><td>network/server_interfaces</td><td>The network interface for DATA function</td><td>eth0</td><td>required</td></tr>
<tr><td>transport</td><td>Default transport mechanism. Supported options: rtrd (RAW Disk Interface), rtlfs (On top of FileSystem)</td><td>rtrd</td><td>required</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" name="section-rtrd"></a><a href="#section-rtrd" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Section &quot;rtrd&quot;</h3>
<p>This file defines device configuration. Recommended for High Performance and better Disk space utilization as there is no filesytem overhead and data blobs written directly to device.</p>
<table>
<thead>
<tr><th>Field</th><th>Description</th><th>Example</th><th>Required</th></tr>
</thead>
<tbody>
<tr><td>devices/name</td><td>Unique device name as listed in /dev/disk/by-id/NAME</td><td>ata-MICRON_M510DC_MTFDDAK800MBP_15351133916C</td><td>required</td></tr>
<tr><td>devices/device</td><td>Kernel device name (used only for device description)</td><td>/dev/sdb</td><td>required</td></tr>
<tr><td>devices/journal</td><td>Unique device name as listed in /dev/disk/by-id/NAME (SSD) to be used as WAL journal and caching</td><td>ata-MICRON_M510DC_MTFDDAK800MBP_1535113391A2</td><td>optional</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" name="section-rtlfs"></a><a href="#section-rtlfs" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Section &quot;rtlfs&quot;</h3>
<p>This file defines device configuration.</p>
<table>
<thead>
<tr><th>Field</th><th>Description</th><th>Example</th><th>Required</th></tr>
</thead>
<tbody>
<tr><td>devices/name</td><td>Unique device name as listed in /dev/disk/by-id/NAME</td><td>disk1</td><td>required</td></tr>
<tr><td>devices/path</td><td>Mountpoint to use. Supported file systems: EXT4, XFS and ZFS</td><td>/data/disk1</td><td>required</td></tr>
<tr><td>devices/device</td><td>Kernel device name (used only for device description)</td><td>/dev/sdb</td><td>required</td></tr>
</tbody>
</table>
<h3><a class="anchor" aria-hidden="true" name="section-auditd"></a><a href="#section-auditd" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Section &quot;auditd&quot;</h3>
<p>This file defines StatsD protocol compatible statistic aggregator configuration.</p>
<table>
<thead>
<tr><th>Field</th><th>Description</th><th>Example</th><th>Required</th></tr>
</thead>
<tbody>
<tr><td>is_aggregator</td><td>Marks Data Container to become an aggregator and primary management endpoint</td><td>0</td><td>required</td></tr>
</tbody>
</table>
<h2><a class="anchor" aria-hidden="true" name="modifications-to-host-os-sysctl"></a><a href="#modifications-to-host-os-sysctl" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Modifications to host OS sysctl</h2>
<p>To achieve best performance / reliability results some host parameters needs to be adjusted.</p>
<h3><a class="anchor" aria-hidden="true" name="recommended-modifications"></a><a href="#recommended-modifications" aria-hidden="true" class="hash-link" ><svg aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Recommended modifications</h3>
<p>This section defines parameters which recommended for optimal performance.</p>
<table>
<thead>
<tr><th>Field</th><th>Description</th><th>Value</th><th>Required</th></tr>
</thead>
<tbody>
<tr><td>net.ipv6.conf.all.force_mld_version</td><td>Version of MLD protocol</td><td>1</td><td>required</td></tr>
<tr><td>vm.dirty_ratio</td><td>Percentage of system memory which when dirty, the process doing writes would block and write out dirty pages to the disks</td><td>10</td><td>required for hosts running Data containers</td></tr>
<tr><td>vm.dirty_background_ratio</td><td>Percentage of system memory which when dirty then system can start writing data to the disks</td><td>5</td><td>required for hosts running Data containers</td></tr>
<tr><td>vm.dirty_expire_centisecs</td><td>Defines when dirty data is old enough to be eligible for writeout to disks</td><td>6000</td><td>required for hosts running Data containers</td></tr>
<tr><td>vm.swappiness</td><td>Defines how aggressive the kernel will swap memory pages</td><td>25</td><td>required for hosts running Data containers</td></tr>
<tr><td>net.core.optmem_max</td><td>Maximum amount of option memory buffers</td><td>131072</td><td>required for 10G+ networks</td></tr>
<tr><td>net.core.netdev_max_backlog</td><td>Maximum amount of incoming packets for backlog queue</td><td>300000</td><td>required for 10G+ networks</td></tr>
<tr><td>net.core.rmem_default</td><td>Default socket receive buffer</td><td>80331648</td><td>required for 10G+ networks</td></tr>
<tr><td>net.core.rmem_max</td><td>Maximum socket receive buffer</td><td>80331648</td><td>required for 10G+ networks</td></tr>
<tr><td>net.core.wmem_default</td><td>Default socket send buffer</td><td>33554432</td><td>required for 10G+ networks</td></tr>
<tr><td>net.core.wmem_max</td><td>Maximum socket send buffer</td><td>50331648</td><td>required for 10G+ networks</td></tr>
<tr><td>net.ipv6.ip6frag_high_thresh</td><td>Maximum amount of memory to use to reassemble IP fragments</td><td>10000000</td><td>required for 10G+ networks</td></tr>
<tr><td>net.ipv6.ip6frag_low_thresh</td><td>Lower limit at which packets should start being assembled again</td><td>7000000</td><td>required for 10G+ networks</td></tr>
<tr><td>net.ipv6.ip6frag_time</td><td>Tells the IP fragmentation handler how long to keep an IP fragment in memory, counted in seconds</td><td>120</td><td>required for 10G+ networks</td></tr>
</tbody>
</table>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="introduction.html">← Introduction</a><a class="docs-next button" href="installation-ui.html">Installation NexentaEdge DevOps Edition UI →</a></div></div></div></div><footer class="nav-footer" id="footer"><section style="font-size:16px;display:flex;flex-direction:column;align-items:center;padding-top:10px;"><img src="/img/logo-nexenta-edge.png" style="height:60px;margin-bottom:10px;"/><a href="https://nexenta.com/products/nexentaedge" style="padding-bottom:20px;">NexentaEdge Product Page</a></section><section class="copyright">Copyright © 2018 Nexenta Systems, Inc.</section></footer></div><script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/1/docsearch.min.js"></script><script>
              var search = docsearch({
                apiKey: '839b05a95d1375c54722a0161e78d578',
                indexName: 'nexentaedge',
                inputSelector: '#search_input_react'
              });
            </script></body></html>